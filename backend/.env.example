# ========================================
# LLM 提供商配置
# ========================================
# 支持的提供商: openai, anthropic, deepseek, siliconflow 等
# 所有兼容 OpenAI API 格式的提供商都可以使用

# 主要 LLM 提供商
LLM_PROVIDER=siliconflow
LLM_API_KEY=sk-your-api-key-here
LLM_BASE_URL=https://api.siliconflow.cn/v1
LLM_CHAT_MODEL=moonshotai/Kimi-K2-Thinking

# ========================================
# Embeddings 配置
# ========================================
# 可以使用与 LLM 不同的提供商（例如使用更便宜的服务）
# 如果不设置 EMBEDDING_API_KEY 和 EMBEDDING_BASE_URL，将使用 LLM 的配置

EMBEDDING_PROVIDER=siliconflow
EMBEDDING_MODEL=Qwen/Qwen3-Embedding-8B
EMBEDDING_DIMENSION=4096

# 如果 Embeddings 使用不同的提供商，取消注释以下配置：
# EMBEDDING_API_KEY=sk-your-embedding-api-key
# EMBEDDING_BASE_URL=https://api.your-embedding-provider.com/v1

# ========================================
# Rerank 配置
# ========================================
# 重排序功能，用于提升检索结果的相关性

RERANK_ENABLED=true
RERANK_MODEL=Qwen/Qwen3-Reranker-8B
RERANK_TOP_N=5
RERANK_INSTRUCTION=根据查询对商品进行相关性排序

# 如果 Rerank 使用不同的提供商，取消注释以下配置：
# RERANK_PROVIDER=siliconflow
# RERANK_API_KEY=sk-your-rerank-api-key
# RERANK_BASE_URL=https://api.your-rerank-provider.com/v1

# ========================================
# 模型能力配置
# ========================================
# 手动指定模型能力（JSON 格式），会覆盖 models.dev 的配置
# 示例：
# MODEL_PROFILES_JSON={"moonshotai/Kimi-K2-Thinking": {"reasoning_output": true, "tool_calling": true, "structured_output": true}}
MODEL_PROFILES_JSON=

# models.dev 配置（自动获取模型能力信息）
MODELS_DEV_ENABLED=true
MODELS_DEV_API_URL=https://models.dev/api.json
# MODELS_DEV_PROVIDER_ID 默认使用 LLM_PROVIDER，也可以手动指定
# MODELS_DEV_PROVIDER_ID=siliconflow
MODELS_DEV_TIMEOUT_SECONDS=10.0
MODELS_DEV_CACHE_TTL_SECONDS=86400.0

# ========================================
# Qdrant 向量数据库配置
# ========================================
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION=products

# ========================================
# 数据库配置
# ========================================
DATABASE_PATH=./data/app.db
CHECKPOINT_DB_PATH=./data/checkpoints.db

# ========================================
# 文本处理配置
# ========================================
CHUNK_SIZE=800
CHUNK_OVERLAP=100

# ========================================
# 服务配置
# ========================================
API_HOST=0.0.0.0
API_PORT=8000
CORS_ORIGINS=http://localhost:3000

# ========================================
# 日志配置
# ========================================
LOG_LEVEL=DEBUG
LOG_MODE=detailed
LOG_FILE=./logs/app.log
LOG_FILE_ROTATION=10 MB
LOG_FILE_RETENTION=7 days

# ========================================
# 聊天模式配置
# ========================================
# natural: 商品推荐助手模式（默认），专注商品推荐，非商品问题引导回商品
# free: 自由聊天模式，可聊任何话题，工具可用但不强制
# strict: 严格模式，必须基于工具输出或历史对话回答，否则返回受控失败
CHAT_MODE=natural

# ========================================
# 多提供商配置示例
# ========================================

# 示例 1: 使用 OpenAI
# LLM_PROVIDER=openai
# LLM_API_KEY=sk-your-openai-key
# LLM_BASE_URL=https://api.openai.com/v1
# LLM_CHAT_MODEL=gpt-4
# EMBEDDING_MODEL=text-embedding-3-large
# EMBEDDING_DIMENSION=3072

# 示例 2: 使用 DeepSeek
# LLM_PROVIDER=deepseek
# LLM_API_KEY=sk-your-deepseek-key
# LLM_BASE_URL=https://api.deepseek.com/v1
# LLM_CHAT_MODEL=deepseek-chat
# EMBEDDING_MODEL=deepseek-embedding
# EMBEDDING_DIMENSION=1536

# 示例 3: 使用 Anthropic
# LLM_PROVIDER=anthropic
# LLM_API_KEY=sk-your-anthropic-key
# LLM_BASE_URL=https://api.anthropic.com/v1
# LLM_CHAT_MODEL=claude-3-5-sonnet-20241022

# 示例 4: 混合使用（LLM 用 OpenAI，Embeddings 用 SiliconFlow）
# LLM_PROVIDER=openai
# LLM_API_KEY=sk-your-openai-key
# LLM_BASE_URL=https://api.openai.com/v1
# LLM_CHAT_MODEL=gpt-4
# 
# EMBEDDING_PROVIDER=siliconflow
# EMBEDDING_API_KEY=sk-your-siliconflow-key
# EMBEDDING_BASE_URL=https://api.siliconflow.cn/v1
# EMBEDDING_MODEL=Qwen/Qwen3-Embedding-8B
# EMBEDDING_DIMENSION=4096