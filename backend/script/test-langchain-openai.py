"""
LangChain + SiliconFlow ç¡…åŸºæµåŠ¨é›†æˆç¤ºä¾‹
ä½¿ç”¨ SiliconFlow çš„ API æ„å»ºæ™ºèƒ½ä»£ç†
"""

from langchain_openai import ChatOpenAI

# from langchain.chat_models import init_chat_model
from langchain.agents import create_agent
from langchain.tools import tool


@tool
def get_weather(city: str) -> str:
    """è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯"""
    # æ¨¡æ‹Ÿå¤©æ°”APIè°ƒç”¨ - å®é™…åº”ç”¨ä¸­å¯ä»¥è°ƒç”¨çœŸå®çš„å¤©æ°”API
    weather_data = {
        "åŒ—äº¬": "æ™´å¤©ï¼Œæ¸©åº¦25Â°Cï¼Œæ¹¿åº¦45%",
        "ä¸Šæµ·": "å¤šäº‘ï¼Œæ¸©åº¦22Â°Cï¼Œæ¹¿åº¦60%",
        "æ·±åœ³": "é›¨å¤©ï¼Œæ¸©åº¦28Â°Cï¼Œæ¹¿åº¦80%",
        "å¹¿å·": "é˜´å¤©ï¼Œæ¸©åº¦26Â°Cï¼Œæ¹¿åº¦70%",
        "æ­å·": "å°é›¨ï¼Œæ¸©åº¦20Â°Cï¼Œæ¹¿åº¦75%",
        "sf": "Sunny in San Francisco, 72Â°F",  # å…¼å®¹è‹±æ–‡æŸ¥è¯¢
        "san francisco": "Sunny in San Francisco, 72Â°F",
    }
    return weather_data.get(city.lower(), f"{city}çš„å¤©æ°”ä¿¡æ¯ï¼šæ™´å¤©ï¼Œæ¸©åº¦20-25Â°C")


@tool
def calculate_math(expression: str) -> str:
    """è®¡ç®—æ•°å­¦è¡¨è¾¾å¼"""
    try:
        # æ³¨æ„ï¼šå®é™…åº”ç”¨ä¸­åº”è¯¥ä½¿ç”¨æ›´å®‰å…¨çš„è®¡ç®—æ–¹å¼
        result = eval(expression)
        return f"è®¡ç®—ç»“æœï¼š{expression} = {result}"
    except Exception as e:
        return f"è®¡ç®—é”™è¯¯ï¼š{str(e)}"


@tool
def search_info(query: str) -> str:
    """æœç´¢ç›¸å…³ä¿¡æ¯"""
    # æ¨¡æ‹Ÿæœç´¢åŠŸèƒ½ - å®é™…åº”ç”¨ä¸­å¯ä»¥è°ƒç”¨æœç´¢å¼•æ“API
    search_results = {
        "äººå·¥æ™ºèƒ½": "äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºèƒ½å¤Ÿæ¨¡æ‹Ÿäººç±»æ™ºèƒ½çš„æœºå™¨ã€‚",
        "æœºå™¨å­¦ä¹ ": "æœºå™¨å­¦ä¹ æ˜¯AIçš„ä¸€ä¸ªå­é›†ï¼Œé€šè¿‡ç®—æ³•è®©è®¡ç®—æœºä»æ•°æ®ä¸­å­¦ä¹ å¹¶åšå‡ºé¢„æµ‹ã€‚",
        "æ·±åº¦å­¦ä¹ ": "æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œæ¨¡æ‹Ÿäººè„‘å¤„ç†ä¿¡æ¯çš„æ–¹å¼ã€‚",
        "ç¡…åŸºæµåŠ¨": "ç¡…åŸºæµåŠ¨æ˜¯ä¸€å®¶æä¾›AIæ¨¡å‹APIæœåŠ¡çš„äº‘å¹³å°ã€‚",
    }

    for key, value in search_results.items():
        if key in query:
            return f"æœç´¢ç»“æœï¼š{value}"

    return f"ä¸ºæŸ¥è¯¢ '{query}' æ‰¾åˆ°çš„ç›¸å…³ä¿¡æ¯ï¼Œè¯·ä½¿ç”¨æ›´å…·ä½“çš„å…³é”®è¯ã€‚"


def main():
    """ä¸»å‡½æ•°ï¼šæ¼”ç¤º LangChain + SiliconFlow çš„æ™ºèƒ½ä»£ç†"""

    print("ğŸš€ LangChain + SiliconFlow ç¡…åŸºæµåŠ¨é›†æˆç¤ºä¾‹")
    print("=" * 60)

    # åˆå§‹åŒ– SiliconFlow ChatOpenAI æ¨¡å‹
    siliconflow_model = ChatOpenAI(
        model="moonshotai/Kimi-K2-Thinking",  # ä½¿ç”¨ SiliconFlow æ”¯æŒçš„æ¨¡å‹
        openai_api_key="sk-jxkuiiukbesibqapqognjxgxodhjnjzjzcfpkmgnowsdlrqx",  # SiliconFlow API Key
        openai_api_base="https://api.siliconflow.cn/v1",  # SiliconFlow åŸºç¡€URL
        temperature=0.7,
        max_tokens=1500,
        verbose=True,
    )

    print("ğŸ¤– åˆå§‹åŒ– SiliconFlow æ¨¡å‹å®Œæˆ")
    print(f"ğŸ“‹ ä½¿ç”¨çš„æ¨¡å‹: moonshotai/Kimi-K2-Thinking")
    print(f"ğŸŒ API ç«¯ç‚¹: https://api.siliconflow.cn/v1")
    print()

    # é¦–å…ˆæµ‹è¯•æ¨¡å‹çš„æµå¼åŠŸèƒ½ï¼ˆå­¦ä¹  2.pyï¼‰
    print("ğŸ§ª å…ˆæµ‹è¯•æ¨¡å‹çš„æµå¼åŠŸèƒ½...")
    test_question = "ç®€å•ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½"
    print(f"â“ æµ‹è¯•é—®é¢˜: {test_question}")

    try:
        print(f"ğŸ¤– AI å›å¤ï¼š", end="", flush=True)

        full_response = ""
        reasoning_content = ""

        # ç›´æ¥ä½¿ç”¨æ¨¡å‹çš„æµå¼è°ƒç”¨ï¼ˆå­¦ä¹  2.py çš„æ–¹å¼ï¼‰
        stream_response = siliconflow_model.stream([{"role": "user", "content": test_question}])

        # å¤„ç†æµå¼å“åº”ï¼Œå‚è€ƒ 2.py çš„å®ç°
        for chunk in stream_response:
            print(f"chunk: {chunk}")  # è°ƒè¯•è¾“å‡º

            # LangChain AIMessageChunk å¤„ç†
            if hasattr(chunk, "content") and chunk.content:
                content_part = chunk.content
                print(content_part, end="", flush=True)
                full_response += content_part

            # å¤„ç†æ¨ç†å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
            if (
                hasattr(chunk, "additional_kwargs")
                and "reasoning_content" in chunk.additional_kwargs
            ):
                reasoning_part = chunk.additional_kwargs["reasoning_content"]
                print(f"\nğŸ§  æ¨ç†è¿‡ç¨‹: {reasoning_part}", end="", flush=True)
                reasoning_content += reasoning_part

        print(f"\n\nâœ… æ¨¡å‹æµå¼æµ‹è¯•å®Œæˆï¼")
        print(f"ğŸ“Š å“åº”æ€»é•¿åº¦: {len(full_response)} å­—ç¬¦")
        if reasoning_content:
            print(f"ğŸ§  æ¨ç†å†…å®¹é•¿åº¦: {len(reasoning_content)} å­—ç¬¦")

    except Exception as e:
        print(f"\nâŒ æ¨¡å‹æµå¼æµ‹è¯•å¤±è´¥: {str(e)}")
        return

    print("\n" + "=" * 60)

    # åˆ›å»ºæ™ºèƒ½ä»£ç†
    agent = create_agent(
        model=siliconflow_model,
        tools=[get_weather, calculate_math, search_info],
        system_prompt="""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œä½¿ç”¨ SiliconFlow çš„ AI æ¨¡å‹æä¾›æœåŠ¡ã€‚
ä½ å¯ä»¥è°ƒç”¨ä»¥ä¸‹å·¥å…·æ¥å¸®åŠ©ç”¨æˆ·ï¼š
- get_weather: è·å–å¤©æ°”ä¿¡æ¯
- calculate_math: è®¡ç®—æ•°å­¦è¡¨è¾¾å¼
- search_info: æœç´¢ç›¸å…³ä¿¡æ¯

è¯·ç”¨ä¸­æ–‡å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œå¹¶æ ¹æ®éœ€è¦è°ƒç”¨åˆé€‚çš„å·¥å…·ã€‚""",
    )

    print("ğŸ› ï¸ åˆ›å»ºæ™ºèƒ½ä»£ç†å®Œæˆ")
    print("ğŸ“‹ å¯ç”¨å·¥å…·: get_weather, calculate_math, search_info")
    print()

    # æµ‹è¯•é—®é¢˜åˆ—è¡¨
    test_questions = [
        "åŒ—äº¬ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
        "è®¡ç®— 15 + 27 ç­‰äºå¤šå°‘ï¼Ÿ",
        "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
        "è¯·å¸®æˆ‘æŸ¥è¯¢æ­å·çš„å¤©æ°”",
        "è®¡ç®— (2 + 3) * 4 çš„ç»“æœ",
    ]

    print("ğŸ§ª å¼€å§‹æµ‹è¯•æ™ºèƒ½ä»£ç†åŠŸèƒ½...")
    print()

    for i, question in enumerate(test_questions, 1):
        print(f"â“ æµ‹è¯• {i}: {question}")

        try:
            # ä½¿ç”¨æµå¼è°ƒç”¨ï¼Œå­¦ä¹  2.py çš„ chunk å¤„ç†æ–¹å¼
            print(f"ğŸ¤– AI å›å¤ï¼š", end="", flush=True)

            full_response = ""
            reasoning_content = ""

            # ç›´æ¥ä½¿ç”¨æ¨¡å‹çš„æµå¼è°ƒç”¨ï¼ˆå­¦ä¹  2.py çš„æ–¹å¼ï¼‰
            stream_response = siliconflow_model.stream([{"role": "user", "content": question}])

            # å¤„ç†æµå¼å“åº”ï¼Œå‚è€ƒ 2.py çš„å®ç°
            for chunk in stream_response:
                print(f"chunk: {chunk}")  # è°ƒè¯•è¾“å‡º

                # LangChain AIMessageChunk å¤„ç†
                if hasattr(chunk, "content") and chunk.content:
                    content_part = chunk.content
                    print(content_part, end="", flush=True)
                    full_response += content_part

                # å¤„ç†æ¨ç†å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
                if (
                    hasattr(chunk, "additional_kwargs")
                    and "reasoning_content" in chunk.additional_kwargs
                ):
                    reasoning_part = chunk.additional_kwargs["reasoning_content"]
                    print(f"\nğŸ§  æ¨ç†è¿‡ç¨‹: {reasoning_part}", end="", flush=True)
                    reasoning_content += reasoning_part

            print(f"\n\nâœ… è°ƒç”¨å®Œæˆï¼")
            print(f"ğŸ“Š å“åº”æ€»é•¿åº¦: {len(full_response)} å­—ç¬¦")
            if reasoning_content:
                print(f"ğŸ§  æ¨ç†å†…å®¹é•¿åº¦: {len(reasoning_content)} å­—ç¬¦")
            print("âœ… æˆåŠŸ")

        except Exception as e:
            print(f"âŒ é”™è¯¯: {str(e)}")
            print("âš ï¸ å¯èƒ½çš„åŸå› : API å¯†é’¥æ— æ•ˆã€ç½‘ç»œè¿æ¥é—®é¢˜æˆ–æ¨¡å‹ä¸å¯ç”¨")

        print("-" * 50)
        print()

    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    print("\nğŸ’¡ ä½¿ç”¨ SiliconFlow çš„ä¼˜åŠ¿:")
    print("  â€¢ ç¨³å®šçš„ API æœåŠ¡")
    print("  â€¢ æ”¯æŒå¤šç§ä¸»æµæ¨¡å‹")
    print("  â€¢ çµæ´»çš„è®¡è´¹æ–¹å¼")
    print("  â€¢ è‰¯å¥½çš„ä¸­æ–‡æ”¯æŒ")
    print("\nğŸ”— äº†è§£æ›´å¤š: https://siliconflow.cn/")


if __name__ == "__main__":
    main()
