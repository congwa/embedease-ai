"""æµå“åº”å¤„ç†å™¨ - è§£æ Agent æµè¾“å‡ºï¼Œå‘å°„äº‹ä»¶

ä½¿ç”¨æ–¹å¼ï¼š
    from app.services.agent.streams import StreamingResponseHandler

    # ä¼ å…¥ modelï¼Œè‡ªåŠ¨æ£€æµ‹ç‰ˆæœ¬
    handler = StreamingResponseHandler(emitter=context.emitter, model=model)

    async for msg in agent.astream(...):
        await handler.handle_message(msg)
    result = await handler.finalize()

èŒè´£ï¼š
    1. è§£æ AIMessageChunk/AIMessage/ToolMessage
    2. æŒ‰å—ç±»å‹åˆ†æµï¼štext â†’ æ­£æ–‡å¢é‡ï¼Œreasoning â†’ æ¨ç†å¢é‡
    3. å‘å°„å¯¹åº”çš„äº‹ä»¶åˆ° emitter
    4. æ±‡æ€»æœ€ç»ˆç»“æœ

ç‰ˆæœ¬è‡ªåŠ¨æ£€æµ‹ï¼š
    - æ ¹æ® model çš„ _chat_model_version å±æ€§è‡ªåŠ¨åˆ¤æ–­
    - v1 æ¨¡å‹ï¼šä½¿ç”¨ parse_content_blocks() ä» content_blocks æå–
    - v0 æ¨¡å‹ï¼šä½¿ç”¨ model.extract_reasoning() ä»è‡ªå®šä¹‰å±æ€§æå–
    - æ—  model æ—¶é»˜è®¤ä½¿ç”¨ v1
"""

import json
from dataclasses import dataclass, field
from typing import Any

from langchain_core.messages import AIMessage, AIMessageChunk, ToolMessage

from app.core.logging import get_logger
from app.schemas.events import StreamEventType

logger = get_logger("streams.handler")


def normalize_products_payload(payload: Any) -> list[dict[str, Any]] | None:
    """æ ‡å‡†åŒ–å•†å“æ•°æ®æ ¼å¼

    Args:
        payload: åŸå§‹å•†å“æ•°æ®ï¼ˆå¯èƒ½æ˜¯ dict æˆ– listï¼‰

    Returns:
        æ ‡å‡†åŒ–åçš„å•†å“åˆ—è¡¨ï¼Œæˆ– None
    """
    if payload is None:
        return None

    candidate: Any = payload
    if (
        isinstance(candidate, dict)
        and "products" in candidate
        and isinstance(candidate.get("products"), list)
    ):
        candidate = candidate.get("products")

    if not isinstance(candidate, list):
        return None

    normalized: list[dict[str, Any]] = []
    for item in candidate:
        if not isinstance(item, dict):
            continue
        raw_id = item.get("id")
        if raw_id is None:
            continue
        normalized_item = dict(item)
        normalized_item["id"] = str(raw_id)
        normalized.append(normalized_item)

    return normalized or None


@dataclass
class StreamingResponseHandler:
    """æµå“åº”å¤„ç†å™¨ï¼ˆæ ¹æ® model è‡ªåŠ¨æ£€æµ‹ç‰ˆæœ¬ï¼‰

    Attributes:
        emitter: äº‹ä»¶å‘å°„å™¨ï¼ˆéœ€è¦æœ‰ aemit æ–¹æ³•ï¼‰
        model: LLM æ¨¡å‹å®ä¾‹ï¼ˆç”¨äºç‰ˆæœ¬æ£€æµ‹å’Œ v0 æ¨¡å¼çš„ extract_reasoningï¼‰
        conversation_id: ä¼šè¯ IDï¼ˆç”¨äºæ—¥å¿—ï¼‰
    """

    emitter: Any
    model: Any = None
    conversation_id: str = ""

    # å†…éƒ¨çŠ¶æ€
    full_content: str = field(default="", init=False)
    full_reasoning: str = field(default="", init=False)
    products_data: list[dict[str, Any]] | None = field(default=None, init=False)
    seen_tool_ids: set[str] = field(default_factory=set, init=False)

    # ç»Ÿè®¡
    content_events: int = field(default=0, init=False)
    reasoning_events: int = field(default=0, init=False)
    reasoning_chars: int = field(default=0, init=False)

    async def handle_message(self, msg: Any) -> None:
        """å¤„ç†å•æ¡æ¶ˆæ¯ï¼ˆæ ¸å¿ƒåˆ†å‘é€»è¾‘ï¼‰

        Args:
            msg: LangChain æ¶ˆæ¯å¯¹è±¡
        """
        if isinstance(msg, AIMessageChunk):
            await self._handle_ai_chunk(msg)
        elif isinstance(msg, AIMessage):
            await self._handle_ai_message(msg)
        elif isinstance(msg, ToolMessage):
            await self._handle_tool_message(msg)

    def _is_v1_model(self) -> bool:
        """æ£€æµ‹æ˜¯å¦ä½¿ç”¨ v1 æ¨¡å¼"""
        from app.core.chat_models import is_v1_model
        return is_v1_model(self.model)

    async def _handle_ai_chunk(self, msg: AIMessageChunk) -> None:
        """å¤„ç† AI å¢é‡æ¶ˆæ¯"""
        if self._is_v1_model():
            await self._handle_ai_chunk_v1(msg)
        else:
            await self._handle_ai_chunk_v0(msg)

    async def _handle_ai_chunk_v1(self, msg: AIMessageChunk) -> None:
        """v1ï¼šä½¿ç”¨ content_blocks è§£æ"""
        from app.core.chat_models import parse_content_blocks

        parsed = parse_content_blocks(msg)

        # æ–‡æœ¬å¢é‡
        text_delta = parsed.text
        if text_delta:
            self.full_content += text_delta
            self.content_events += 1
            await self.emitter.aemit(
                StreamEventType.ASSISTANT_DELTA.value,
                {"delta": text_delta},
            )

        # æ¨ç†å¢é‡
        reasoning_delta = parsed.reasoning
        if reasoning_delta:
            self.full_reasoning += reasoning_delta
            self.reasoning_chars += len(reasoning_delta)
            self.reasoning_events += 1
            await self.emitter.aemit(
                StreamEventType.ASSISTANT_REASONING_DELTA.value,
                {"delta": reasoning_delta},
            )

    async def _handle_ai_chunk_v0(self, msg: AIMessageChunk) -> None:
        """v0ï¼šä½¿ç”¨ model.extract_reasoning() è§£æ"""
        # æ­£æ–‡å¢é‡
        delta = msg.content or ""
        if isinstance(delta, list):
            delta = "".join(str(x) for x in delta)
        if isinstance(delta, str) and delta:
            self.full_content += delta
            self.content_events += 1
            await self.emitter.aemit(
                StreamEventType.ASSISTANT_DELTA.value,
                {"delta": delta},
            )

        # æ¨ç†å¢é‡ï¼ˆé€šè¿‡å¤šæ€æ¥å£æå–ï¼‰
        if self.model and hasattr(self.model, "extract_reasoning"):
            reasoning_chunk = self.model.extract_reasoning(msg)
            if reasoning_chunk and reasoning_chunk.delta:
                self.full_reasoning += reasoning_chunk.delta
                self.reasoning_chars += len(reasoning_chunk.delta)
                self.reasoning_events += 1
                await self.emitter.aemit(
                    StreamEventType.ASSISTANT_REASONING_DELTA.value,
                    {"delta": reasoning_chunk.delta},
                )

    async def _handle_ai_message(self, msg: AIMessage) -> None:
        """å¤„ç†å®Œæ•´ AI æ¶ˆæ¯ï¼ˆå…œåº•åœºæ™¯ï¼‰"""
        if self._is_v1_model():
            await self._handle_ai_message_v1(msg)
        else:
            await self._handle_ai_message_v0(msg)

    async def _handle_ai_message_v1(self, msg: AIMessage) -> None:
        """v1ï¼šä½¿ç”¨ content_blocks è§£æï¼ˆå…œåº•ï¼‰"""
        from app.core.chat_models import parse_content_blocks

        parsed = parse_content_blocks(msg)

        # å…œåº•ï¼šå¦‚æœä¹‹å‰æ²¡æœ‰æ”¶åˆ°ä»»ä½• content chunk
        if self.content_events == 0:
            text_delta = parsed.text
            if text_delta:
                self.full_content += text_delta
                self.content_events += 1
                await self.emitter.aemit(
                    StreamEventType.ASSISTANT_DELTA.value,
                    {"delta": text_delta},
                )

        # å…œåº•ï¼šä»å®Œæ•´ AIMessage æå–æ¨ç†
        if self.reasoning_events == 0:
            reasoning_delta = parsed.reasoning
            if reasoning_delta:
                self.full_reasoning += reasoning_delta
                self.reasoning_chars += len(reasoning_delta)
                self.reasoning_events += 1
                await self.emitter.aemit(
                    StreamEventType.ASSISTANT_REASONING_DELTA.value,
                    {"delta": reasoning_delta},
                )

    async def _handle_ai_message_v0(self, msg: AIMessage) -> None:
        """v0ï¼šä½¿ç”¨ model.extract_reasoning() è§£æï¼ˆå…œåº•ï¼‰"""
        # å…œåº•ï¼šå¦‚æœä¹‹å‰æ²¡æœ‰æ”¶åˆ°ä»»ä½• content chunk
        if self.content_events == 0:
            delta = msg.content or ""
            if isinstance(delta, list):
                delta = "".join(str(x) for x in delta)
            if isinstance(delta, str) and delta:
                self.full_content += delta
                self.content_events += 1
                await self.emitter.aemit(
                    StreamEventType.ASSISTANT_DELTA.value,
                    {"delta": delta},
                )

        # å…œåº•ï¼šä»å®Œæ•´ AIMessage æå–æ¨ç†
        if self.reasoning_events == 0 and self.model and hasattr(self.model, "extract_reasoning"):
            reasoning_chunk = self.model.extract_reasoning(msg)
            if reasoning_chunk and reasoning_chunk.delta:
                self.full_reasoning += reasoning_chunk.delta
                self.reasoning_chars += len(reasoning_chunk.delta)
                self.reasoning_events += 1
                await self.emitter.aemit(
                    StreamEventType.ASSISTANT_REASONING_DELTA.value,
                    {"delta": reasoning_chunk.delta},
                )

    async def _handle_tool_message(self, msg: ToolMessage) -> None:
        """å¤„ç†å·¥å…·æ¶ˆæ¯ï¼Œæå–å•†å“æ•°æ®ï¼ˆå»¶è¿Ÿåˆ° finalize é˜¶æ®µç»Ÿä¸€æ¨é€ï¼‰"""
        # å»é‡
        msg_id = getattr(msg, "id", None)
        if isinstance(msg_id, str) and msg_id in self.seen_tool_ids:
            return
        if isinstance(msg_id, str):
            self.seen_tool_ids.add(msg_id)

        content = msg.content
        try:
            parsed_data: Any
            if isinstance(content, str):
                parsed_data = json.loads(content)
            elif isinstance(content, (list, dict)):
                parsed_data = content
            else:
                return

            normalized_products = normalize_products_payload(parsed_data)
            if normalized_products is None:
                return

            # æ”¶é›†å•†å“æ•°æ®ï¼Œå»¶è¿Ÿåˆ° finalize é˜¶æ®µç»Ÿä¸€æ¨é€
            # è¿™æ ·å•†å“æ¨èä¼šåœ¨ Agent æ€»ç»“å®Œæˆåæ‰å±•ç¤ºç»™ç”¨æˆ·
            if self.products_data is None:
                self.products_data = normalized_products
            else:
                # åˆå¹¶å¤šæ¬¡å·¥å…·è°ƒç”¨è¿”å›çš„å•†å“ï¼ˆå»é‡ï¼‰
                seen_ids = {p.get("id") for p in self.products_data}
                for product in normalized_products:
                    if product.get("id") not in seen_ids:
                        self.products_data.append(product)
                        seen_ids.add(product.get("id"))
        except Exception:
            pass

    async def finalize(self) -> dict[str, Any]:
        """å‘é€æœ€ç»ˆäº‹ä»¶ï¼Œè¿”å›æ±‡æ€»æ•°æ®

        Returns:
            åŒ…å« contentã€reasoningã€products çš„å­—å…¸
        """
        # å…œåº•ï¼šä»…å½“"å…¨ç¨‹æ²¡æœ‰ä»»ä½• content delta"æ—¶ï¼Œæ‰æŠŠ reasoning å…œåº•æˆ contentï¼ˆé¿å…æ··æµï¼‰
        if self.content_events == 0 and self.full_reasoning.strip():
            logger.warning(
                "æ£€æµ‹åˆ° content å…¨ç¨‹ä¸ºç©ºï¼Œå…œåº•å°† reasoning ä½œä¸º content è¾“å‡º",
                conversation_id=self.conversation_id,
                content_len=len(self.full_content),
                reasoning_len=len(self.full_reasoning),
            )
            self.full_content = self.full_reasoning
            self.full_reasoning = ""

        # åœ¨æ€»ç»“é˜¶æ®µç»Ÿä¸€æ¨é€å•†å“æ•°æ®ï¼ˆå»¶è¿Ÿæ¨é€ï¼‰
        # è¿™æ ·å•†å“æ¨èä¼šåœ¨ Agent æ€»ç»“å®Œæˆåæ‰å±•ç¤ºç»™ç”¨æˆ·
        if self.products_data:
            await self.emitter.aemit(
                StreamEventType.ASSISTANT_PRODUCTS.value,
                {"items": self.products_data},
            )
            logger.info(
                "ğŸ“¦ æ¨é€å•†å“æ¨èï¼ˆæ€»ç»“é˜¶æ®µï¼‰",
                conversation_id=self.conversation_id,
                product_count=len(self.products_data),
            )

        result = {
            "content": self.full_content,
            "reasoning": self.full_reasoning if self.full_reasoning else None,
            "products": self.products_data
            if isinstance(self.products_data, list) or self.products_data is None
            else [self.products_data],
        }

        await self.emitter.aemit(StreamEventType.ASSISTANT_FINAL.value, result)

        logger.info(
            "âœ… æµå¤„ç†å®Œæˆ",
            conversation_id=self.conversation_id,
            content_events=self.content_events,
            reasoning_events=self.reasoning_events,
            reasoning_chars=self.reasoning_chars,
        )

        return result

    def get_stats(self) -> dict[str, int]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç»Ÿè®¡å­—å…¸
        """
        return {
            "content_events": self.content_events,
            "reasoning_events": self.reasoning_events,
            "reasoning_chars": self.reasoning_chars,
        }
